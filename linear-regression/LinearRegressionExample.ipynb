{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries for linear regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functions to execute regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_split_data():\n",
    "    #read data\n",
    "    df = pd.read_csv(\"ex1data1.txt\", header=None)\n",
    "\n",
    "    #split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[0].values.reshape(-1,1), df[1].values.reshape(-1,1), test_size=0.33)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def plot_data():\n",
    "    df = pd.read_csv(\"ex1data1.txt\", header=None)\n",
    "    # Plot outputs\n",
    "    plt.scatter(df[0], df[1],  color='black')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def regr_fit(regr, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # fit model\n",
    "    regr.fit(X_train, y_train)\n",
    "    \n",
    "def regr_predict(regr, X_test):\n",
    "    \n",
    "    # predit test set\n",
    "    y_pred = regr.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def print_result(y_test,y_pred):\n",
    "    # coef\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    # The mean squared error\n",
    "    print(\"Mean squared error: %.2f\"\n",
    "          % mean_squared_error(y_test, y_pred))\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "    \n",
    "    return mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "def plot_result(X_test, y_test, y_pred):\n",
    "    # Plot outputs\n",
    "    plt.scatter(X_test, y_test,  color='black')\n",
    "    plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_final(epochs, mean_squared):\n",
    "    \n",
    "    plt.plot(epochs, mean_squared,  color='black')\n",
    "    plt.show()\n",
    "    \n",
    "def print_resume(result_scores):\n",
    "    #reduce(lambda x: x+x , result_scores)\n",
    "    print('Average Variance: ', sum(result_scores) / len(result_scores))\n",
    "    print('Minor Variance: ', min(result_scores))\n",
    "    print('Major Variance: ', max(result_scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execute Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGWRJREFUeJzt3X+MI2d9x/HPd/fuJHx3ai57x/WaZG0oCAn4A8gqooWi\ntKE0PVUE+gcCWfRoULccipRURW2KJRoJrQS0gFqpSrQ0EQe2ApWAEtGjkEZUCLWk3Yvyk0Dzo/aR\n6JIcm4rj2JPIrb/9w+PF65uxx94Ze2b8fknWesdj+3u7cx8/+8zzPGPuLgBA/s1NuwAAQDIIdAAo\nCAIdAAqCQAeAgiDQAaAgCHQAKAgCHQAKgkAHgIIg0AGgIHYN28HMrpL0BUmHJbmkVXf/OzO7TdKf\nSDob7PpRdz856LUOHjzolUplRwUDwKw5derUT9z90LD9hga6pIuS/tzdHzCz/ZJOmdm9wWOfdfe/\njVtUpVLR2tpa3N0BAJLMrBVnv6GB7u5nJJ0J7v/MzB6XdMXOygMAJG2kPnQzq0h6o6T7g003mdnD\nZnaXmR1IuDYAwAhiB7qZ7ZP0FUm3uPs5SbdL+nVJb1CnBf/piOctm9mama2dPXs2bBcAQAJiBbqZ\n7VYnzBvu/lVJcvfn3X3T3duSPifpmrDnuvuquy+5+9KhQ0P79AEAYxoa6GZmku6U9Li7f6Zn+5Ge\n3d4t6dHkywMAxBWnhf4WSe+X9Dtm9mBwOyrpU2b2iJk9LOm3Jf1ZmoUCQN40Gg1VKhXNzc2pUqmo\n0Wik+n5xRrl8T5KFPDRwzDkAzLJGo6Hl5WVtbGxIklqtlpaXlyVJ1Wo1lfdkpigApKBWq22FedfG\nxoZqtVpq70mgA0AKTp8+PdL2JBDoAJCCxcXFkbYngUAHgBSsrKyoVCpt21YqlbSyspLaexLoAJCC\narWq1dVVlctlmZnK5bJWV1dTOyEqSebuqb14v6WlJWdxLgAYjZmdcvelYfvRQgeAgiDQAaAgCHQA\nKAgCHcBUTHpa/CyIc8UiAEjUNKbFzwJa6AAmbhrT4mcBgQ5g4qYxLX4WEOgAJm4a0+JnAYEOYOKm\nMS1+FhDoACZuGtPiZwGBDmAqqtWqms2m2u22ms1momE+q0MiGbYIoFBmeUgkLXQAhTLLQyIJdACF\nMstDIgl0AIUyy0MiCXQAhTLLQyIJdACF0h0SubCwsLXtZS972RQrmhwCHUAhXbhwYev++vq6lpeX\nCz98kUAHUDizOtKFQAdQOLM60oVAB1A4szrShUAHUDizOtJlaKCb2VVm9h0z+4GZPWZmNwfbLzez\ne83sieDrgfTLBYDhZnXxL3P3wTuYHZF0xN0fMLP9kk5JepekD0h60d0/YWa3Sjrg7n856LWWlpZ8\nbW0tmcoBYEaY2Sl3Xxq239AWurufcfcHgvs/k/S4pCsk3SDpRLDbCXVCHgAwJSP1oZtZRdIbJd0v\n6bC7nwkeek7S4UQrAwCMJHagm9k+SV+RdIu7n+t9zDv9NqF9N2a2bGZrZrZ29uzZHRULAIgWK9DN\nbLc6Yd5w968Gm58P+te7/ewvhD3X3Vfdfcndlw4dOpREzQCAEHFGuZikOyU97u6f6XnoHknHgvvH\nJH09+fIAAHHFuWLRWyS9X9IjZvZgsO2jkj4h6Z/M7IOSWpLek06JAIA4hga6u39PkkU8fF2y5QAA\nxsVMUQAoCAIdAAqCQAeAgiDQAaAgCHQAKAgCHQAKgkAHgIIg0AEgQqPRUKVS0dzcnCqVSuYvMh1n\npigAzJxGo6Hl5eWti023Wi0tLy9LUmYvlEELHQBC1Gq1rTDv2tjYUK1Wm1JFw81coOftTygA03H6\n9OmRtmfBTAV690+oVqsld9/6E4pQB9BvcXFxpO1ZMFOBnsc/oQBMx8rKikql0rZtpVJJKysrU6po\nuJkK9Dz+CQVgOqrVqlZXV1Uul2VmKpfLWl1dzewJUWnGAj2Pf0IBRZWH81nValXNZlPtdlvNZjPT\nYS7NWKDn8U8ooIg4n5WOmQr0PP4JBRQR57PSYe4+sTdbWlrytbW1ib0fgGyam5tTWPaYmdrt9hQq\nyjYzO+XuS8P2m6kWOoBs4HxWOgh0ABPH+ax0EOgAJo7zWemgDx0AMo4+dACYMQQ6ABQEgQ4ABUGg\nAzHkYZo6wBWLgCHyeOUazCZa6MAQTFNHXgwNdDO7y8xeMLNHe7bdZmbPmtmDwe1oumUC08Oyy8iL\nOC30z0u6PmT7Z939DcHtZLJlAdnBNHXkxdBAd/fvSnpxArUAmcQ0deTFTvrQbzKzh4MumQOJVQQk\nbKcjVJimjryINfXfzCqSvuHurw++PyzpJ5Jc0sclHXH3GyOeuyxpWZIWFxevbrVaiRQOxNE/QkXq\ntK4JZORJ3Kn/YwV63Mf6sZYLJq1SqSisEVEul9VsNidfEDCGVNdyMbMjPd++W9KjUfsC08QIFcyS\noROLzOxuSddKOmhmz0j6a0nXmtkb1OlyaUr60xRrBMa2uLgY2kJnhAqKaGigu/v7QjbfmUItQOJW\nVlZC+9AZoYIiYqYoCo0RKpglXOACADKOC1zkHKv7ARgVgZ5B3bHTrVZL7r61uh+hHo0PQIAul0xi\n7PRomDyEokt0YlFSCPR45ubmFPZ7MTO12+0pVJRtfACi6OhDzzFW9xsNk4eADgI9g1jdbzR8AAId\nBHoGMXZ6NHwAAh30oaMQGo2GarWaTp8+rcXFRa2srPABiMLgpCgAFAQnRQFgxhDoAFAQBHqBMFsy\nW/h9YNII9AwbJRBYLiBb+H1gKtx9Yrerr77a86xer3u5XHYz83K57PV6PbX3kORm5upcRMQlealU\ninzP7nP6b+VyOfEaMRy/DyRJ0prHyFhGucQ0ifVCwt6jX9R0dpYLyBZ+H0gSo1wSVqvVLgnajY0N\n1Wq1VN+jX9R0dmZLZgu/D0wDgR7TJNYLifNaUYHAbMls4feBaSDQY5pEi2vYaw0KBJYLyBZ+H5iK\nOB3tSd3yfFK0Xq97qVSKfZIyqffonhhN6yQsgOxTzJOitNBjmkSLK+w9vvjFL8rd1Ww2ad0BGIhR\nLgCQcYxyAYAZQ6ADQEEQ6ABQEAQ6ABQEgQ4ABTE00M3sLjN7wcwe7dl2uZnda2ZPBF8PpFsmMBzL\n1WLWxWmhf17S9X3bbpV0n7u/WtJ9wffA1LBcLRBzHLqZVSR9w91fH3z/I0nXuvsZMzsi6d/d/TXD\nXodx6EhLpVJRq9W6ZHvU6pRAnqQ9Dv2wu58J7j8n6fCAQpbNbM3M1s6ePTvm2wGDTWLxNCDrdnxS\nNFhnILKZ7+6r7r7k7kuHDh3a6dsBoViuFhg/0J8PuloUfH0huZKA0bFcLTB+oN8j6Vhw/5ikrydT\nDjAelqsF4g1bvFvSf0p6jZk9Y2YflPQJSb9rZk9Ienvw/dQwXA1SJ9Sbzaba7Xbk6pQcKyiyXcN2\ncPf3RTx0XcK1jKX/Opzd4WqSaJ1hG44VFF3ul89luBri4lhBXs3M8rkMV0NcHCsoutwHOsPVEBfH\nCoou94HOcDXExbGCost9oDNcDXFxrKDocn9SFACKbmZOiiKfGA8OJG/oOHQgaYwHB9JBCx2XSLv1\nXKvVtsK8a2NjQ7VaLdH3AWYNLXRsM4nWM+PBgXTQQp8xw1rfk2g9Mx4cSAeBPkPiXKZtEq1nxoMD\n6Sh0oOdxJEWaNcdpfU+i9cx4cCAl7j6x29VXX+2TUq/XvVQqda+m5JK8VCp5vV6fWA2jSrtmM9v2\n2t2bme2ohnq97uVy2c3My+Vypn/GQB5JWvMYGVvYQC+Xy6HhVS6XJ1bDqNKuOe7rjxLQefzgBPIm\nbqAXtstlmiMpxu022UnNcd4zjb5rhiACGRIn9ZO6TbKFvrCwENoaXVhYSPV9o1qsx48fH9rqHbeF\nPkoreVDru16vh/7cBrW443TjANgZzXqXy6iBnlQ/cFQo9wdfb0h233vYfqO+5yhdNWEfCnFeK49d\nW0DezHygj9JyTLIfOOp9o0Iv7L27rxH3gyWJVnJUMA97LfrQgfTNfKCP0nJMspU5LBj7QzKJ907i\nNYZ9EA16LUa5AOma+UAfpeWYZD/woBZ3WEgm8d5JtJIHfRDR4gama+YD3T1+yzEqzObn58cKsv73\nPX78eGTgJvXXwU5byVF96AsLC4Q5MGUE+ggGnRBMqnUaFbhZ6oOm6wTIpsIE+qRCpl6v+/z8fGJ9\n6aO+d++oHFrFAHrFDfRMTyyKs5hUUqrVqtrtduhjk5iMdOHCha376+vrqf07ARRXpgN9ErMQe2dY\nzs2F/zj6F6ZKegGttP6dWV+cLOv1AbkTpxmf1G3ULpe0ZyHW63Xfs2fPwOF6/f3ZafR5p/HvzFLf\nfJis1wdkiYrQhx41AiSp6fv79u0bOk78+PHjsWraST/7KK+505E7WZnBmfX6gCyZSKBLakp6RNKD\ncd5w1ECPakHv3r17xy25er0+MMyjAiZuazqNFQunNbY+DVmvD8iSSQb6wbj7jzPKJWpNlp225OLO\n6OwPmDhj1tNaU3xas1/TkPX6gCwpTKCn1ZKLu+ZKf8DEGbOeVlhNa32aNGS9PiBLJhXo/yvpAUmn\nJC1H7LMsaU3S2uLi4sj/kDT6lwe9bpyAGTZmPa0PoVE/KLI+USjr9QFZMalAvyL4+nJJD0l626D9\nx51YlHT/ctT+knzfvn2xAmZQaA8K3p2EGK1aYDZNJNC3vZB0m6SPDNpn3Kn/Sfcvj/K6UQaNwAnr\n9zczv+6663YcyLRqgdmTeqBL2itpf8/9/5B0/aDnpLWWy6ARK2mNmghrLe/atWtgF86gVRfDXp/g\nBuAeP9B3MlP0sKTvmdlDkv5L0r+4+7/u4PXG0l0eIEr/LM+kVKtVra6uqlwuS5Lm5uZ08eLFgc/p\n/F4u1Wq1ts2UnOSSBwAKJE7qJ3VLo4U+6ORm2isldh8bdOm2UW5JjJKhZQ8Uj4owU7RrUEgNGn6Y\nVJgP6veOO569e4tzZaBxR8lw0hQopsIE+riBOsqY70EfGMNef5RriJZKJT9+/PjAD4GdXJaOyTpA\nMRUm0IcNAQwbUTJKq3TYB8aw1vIoLfS4HxTjtrSZTg8UU2ECfVALOKzvem5ublswDjOsVTvOB0qc\nVvKw0B6nL5wWOlBMhQn0qJCKmqnZ3zLtXy2x37BWbVTwhl0nVJLv3bv3kgXFBs04TfIEJn3oQDEV\nJtCjQipuN4ekS0K9N0jjXHYuLHjTmg26U4xyAYqnMIHuPlqgRrW2B62EGNaVQ381gKyIG+iZvgTd\nICsrKyqVSrH2dfety7mFXe5Nkubn52VmKpfLWl1dVbVaHfiaUROW0prIBADDZD7Qo2ZNSto2U3OY\n7oWeoy743G631W631Ww2h4a5FP6BUiqVtLKyEqseAEhcnGZ8Urekhy0O2yds/yRHgtBfDWASVJQu\nl6gWde/2Yd0vZqajR49G7tv7+Ciq1aqazeZILXsASEvmAz1OX3XvQllmpr17927b19114sQJNRoN\nVatVHTt2TGYW+jgA5FXmAz1uX3Vva/ngwYOXvM7GxsbWidGTJ092hvhEPA4AeZT5QO+2vhcWFra2\nmZluvvlmzc3NbVt2tmtYN02cbhwAyJvMB3rXhQsXtu7//Oc/1/r6+rZRL72hHtVNMzc3p0ajwZBD\nAIWUi0CPGjve1dtd0mg0dP78+dD9Njc3tby8rKNHjzLkEEDh5CLQ43SFtFqtrTHr6+vrkfttbGzo\n5MmT206ixp1MBABZZv0nB9O0tLTka2trIz+vUqmo1WoN3Gd+fl5XXnnl0P2kTh98u90euQ4AmAYz\nO+XuS8P2y0ULPc40/83NzdgnNbt95Y1GQ5VKJfLkKgDkya5pFxBHtyukVqtFtsC7SwDEaaGfP39e\nH/7wh3XixImtvvneJQXoegGQR7looUu/HGder9cjT2jGXbBrfX1dd9xxxyUnWuOORadlDyCLctFC\n79XbWj99+rQWFxf1qle9SseOHdPm5qbMTPv27dP58+c1Pz+vzc3Nra+9os4dDOu26Z54pWUPIGty\n00Lv1Tsr9OjRo7rvvvu2Atvddf78eR0/flwXL16Uu18S5oMMG4seNoSSWaYAsiCXgd5rdXU1dPvt\nt9++1RUyPz8f67XiLNLFLFMAWZWbQA/rt240GgNb390ZpIP2GXWRLmaZAsiqXIxD7++3lqTdu3er\n3W4P7U6Zn5/XZZddFjrZKKxvXeqMmGk2m7FrKZVKTEwCkJpCjUMP67d+6aWXYvWNb25u6ty5c9qz\nZ8+27aVSKfL5rVYrcvRK/1K9zDIFkBU7CnQzu97MfmRmT5rZrUkV1W+n/dMvvfSS9u/ff0kID7p8\nXdiiX11pXNiCoZAAdizOZY3CbpLmJT0l6ZWS9kh6SNJrBz1nnEvQuce7xNywm5ld8rr1et1LpVKs\nS9elKayOUqnEJe0AuPtkLkF3jaQn3f1pd/+FpC9JumEHrxdpZWVl28nLcYSdtOztPokyidErDIUE\nkISdBPoVkn7c8/0zwbbEVavVyIlAcQxaGrfbfRIV6pMYvcJQSABJSP2kqJktm9mama2dPXt27NeJ\nCtyoMebz8/MjnbSMe6m7NDAUEkASdhLoz0q6quf7K4Nt27j7qrsvufvSoUOHxn6zqMBdXl4O3X7i\nxImRTlpOc/TKND9MABRInI72sJs668A8LekV+uVJ0dcNes64J0W76vW6l8tlNzMvl8tbJw2jtudJ\nEf4NANKhmCdFx16cy90vmtlNkr6lzoiXu9z9sR1/woyhWq3mfhx4Ef4NAKZrR6stuvtJSScTqmUg\nVjkEgMFyMVNUYmgfAAyTm0CPGsIX5wpFADALchPoUUP4zIxp8gCgHAV61GxRd99RtwtrqAAoilws\nn9sVNf3fzNRut0d+PZbCBZAHhVo+tyvp6fmcaAVQJLkK9KRnVLKGCoAiyVWgJz09nzVUABRJrgJd\nSvbiEqyhAqBIchfoSeJycgCKJFejXABgFhVylAsAIFrmA52JPwAQz45WW0wbKywCQHyZbqEz8QcA\n4st0oDPxBwDiy3SgM/EHAOLLdKAz8QcA4st0oDPxBwDiY2IRAGQcE4sAYMYQ6ABQEAQ6ABQEgQ4A\nBUGgA0BBTHSUi5mdldQa8+kHJf0kwXLSRr3py1vN1JuuvNUrxa+57O6Hhu000UDfCTNbizNsJyuo\nN315q5l605W3eqXka6bLBQAKgkAHgILIU6CvTruAEVFv+vJWM/WmK2/1SgnXnJs+dADAYHlqoQMA\nBshcoJtZ08weMbMHzeySlbys4+/N7Ekze9jM3jSNOoNaXhPU2b2dM7Nb+va51sx+2rPPxyZc411m\n9oKZPdqz7XIzu9fMngi+Hoh47rFgnyfM7NiUa/4bM/th8Dv/mpldFvHcgcfPBOu9zcye7fm9H414\n7vVm9qPgeL51ivV+uafWppk9GPHcafx8rzKz75jZD8zsMTO7OdieyeN4QL3pH8PunqmbpKakgwMe\nPyrpm5JM0psl3T/tmoO65iU9p8540d7t10r6xhTrepukN0l6tGfbpyTdGty/VdInQ553uaSng68H\ngvsHpljzOyTtCu5/MqzmOMfPBOu9TdJHYhwzT0l6paQ9kh6S9Npp1Nv3+KclfSxDP98jkt4U3N8v\n6X8kvTarx/GAelM/hjPXQo/hBklf8I7vS7rMzI5MuyhJ10l6yt3HnTiVCnf/rqQX+zbfIOlEcP+E\npHeFPPX3JN3r7i+6+/9JulfS9akV2iOsZnf/trtfDL79vqQrJ1FLHBE/4ziukfSkuz/t7r+Q9CV1\nfjepGlSvmZmk90i6O+064nL3M+7+QHD/Z5Iel3SFMnocR9U7iWM4i4Hukr5tZqfMbDnk8Ssk/bjn\n+2eCbdP2XkX/J/gNM3vIzL5pZq+bZFERDrv7meD+c5IOh+yT1Z+zJN2ozl9pYYYdP5N0U/Dn9V0R\n3QFZ/Bn/lqTn3f2JiMen+vM1s4qkN0q6Xzk4jvvq7ZXKMbxr1AIn4K3u/qyZvVzSvWb2w6BFkVlm\ntkfSOyX9VcjDD6jTDXM+6Ef9Z0mvnmR9g7i7m1luhjqZWU3SRUmNiF2ycvzcLunj6vzn/Lg63Rg3\nTqGOUb1Pg1vnU/v5mtk+SV+RdIu7n+v8MdGRxeO4v96e7akdw5lrobv7s8HXFyR9TZ0/S3s9K+mq\nnu+vDLZN0+9LesDdn+9/wN3Pufv54P5JSbvN7OCkC+zzfLebKvj6Qsg+mfs5m9kHJP2BpKoHnY39\nYhw/E+Huz7v7pru3JX0uoo5M/YzNbJekP5T05ah9pvXzNbPd6oRjw92/GmzO7HEcUW/qx3CmAt3M\n9prZ/u59dU4iPNq32z2S/sg63izppz1/dk1LZKvGzH416JeUmV2jzs98fYK1hblHUvds/zFJXw/Z\n51uS3mFmB4LugncE26bCzK6X9BeS3unuGxH7xDl+JqLvvM67I+r4b0mvNrNXBH/lvVed3820vF3S\nD939mbAHp/XzDf7/3CnpcXf/TM9DmTyOo+qdyDGc5tneMc4Ov1KdM/0PSXpMUi3Y/iFJHwrum6R/\nUGd0wCOSlqZc8151AvpXerb11ntT8G95SJ0TIb854frulnRG0kvq9B9+UNKCpPskPSHp3yRdHuy7\nJOkfe557o6Qng9sfT7nmJ9XpC30wuN0R7Ptrkk4OOn6mVO8Xg+PzYXWC50h/vcH3R9UZBfHUNOsN\ntn++e9z27JuFn+9b1em6erjn9380q8fxgHpTP4aZKQoABZGpLhcAwPgIdAAoCAIdAAqCQAeAgiDQ\nAaAgCHQAKAgCHQAKgkAHgIL4f+9vV7dyxguaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b5c3cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.68496926518\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasvasconcelos/miniconda3/envs/envML/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/lucasvasconcelos/miniconda3/envs/envML/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1000,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-69808a58f379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#plot_result(X_test, y_test, y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mplot_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-19b8fb98b750>\u001b[0m in \u001b[0;36mplot_final\u001b[0;34m(epochs, mean_squared)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envML/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3316\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3318\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3319\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envML/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envML/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envML/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envML/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envML/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 244\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1000,) and (0,)"
     ]
    }
   ],
   "source": [
    "result_scores = []\n",
    "plot_data()\n",
    "# regression from sklearn\n",
    "regr = linear_model.SGDRegressor(alpha= 0.001, n_iter=1000)\n",
    "X_train, X_test, y_train, y_test = read_split_data()\n",
    "regr.fit(X_train,y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "for i in range(1000):\n",
    "    #print('-----------Execution-----------')\n",
    "    #regr.fit(X_train,y_train)\n",
    "    #y_pred = regr.predict(X_test)\n",
    "    #print(regr.coef_)\n",
    "    print('------------------')\n",
    "    #result_scores.append(mean_squared_error(y_test, y_pred) )\n",
    "    #plot_result(X_test, y_test, y_pred)\n",
    "    \n",
    "plot_final(range(1000), result_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "learning rate 0.01 is not supported. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/envML/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_get_learning_rate_type\u001b[0;34m(self, learning_rate)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mLEARNING_RATE_TYPES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0.01",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6c51a66d6071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmystdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_split_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGDRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envML/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loss, penalty, alpha, l1_ratio, fit_intercept, max_iter, tol, shuffle, verbose, epsilon, random_state, learning_rate, eta0, power_t, warm_start, average, n_iter)\u001b[0m\n\u001b[1;32m   1333\u001b[0m                                            \u001b[0meta0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meta0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m                                            \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m                                            average=average, n_iter=n_iter)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/envML/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loss, penalty, alpha, l1_ratio, fit_intercept, max_iter, tol, shuffle, verbose, epsilon, random_state, learning_rate, eta0, power_t, warm_start, average, n_iter)\u001b[0m\n\u001b[1;32m    925\u001b[0m                                                \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m                                                \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                                                n_iter=n_iter)\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     def _partial_fit(self, X, y, alpha, C, loss, learning_rate,\n",
      "\u001b[0;32m~/miniconda3/envs/envML/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loss, penalty, alpha, C, l1_ratio, fit_intercept, max_iter, tol, shuffle, verbose, epsilon, random_state, learning_rate, eta0, power_t, warm_start, average, n_iter)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envML/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# raises ValueError if not registered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_penalty_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_learning_rate_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envML/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_get_learning_rate_type\u001b[0;34m(self, learning_rate)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             raise ValueError(\"learning rate %s \"\n\u001b[0;32m--> 145\u001b[0;31m                              \"is not supported. \" % learning_rate)\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_penalty_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: learning rate 0.01 is not supported. "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = mystdout = StringIO()\n",
    "X_train, X_test, y_train, y_test = read_split_data()\n",
    "regr = linear_model.SGDRegressor(alpha=0, max_iter=1000, verbose=1, learning_rate=0.01)\n",
    "regr.fit(X_train,y_train)\n",
    "sys.stdout = old_stdout\n",
    "loss_history = mystdout.getvalue()\n",
    "print(loss_history)\n",
    "loss_list = []\n",
    "for line in loss_history.split('\\n'):\n",
    "    if(len(line.split(\"loss: \")) == 1):\n",
    "        continue\n",
    "    loss_list.append(float(line.split(\"loss: \")[-1]))\n",
    "plt.plot(np.arange(len(loss_list)), loss_list)\n",
    "plt.xlabel(\"Time in epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
